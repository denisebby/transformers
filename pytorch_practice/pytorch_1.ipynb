{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: Even though we use the PyTorch module, we import it with the name 'torch', which was the original name.\n",
    "import torch # torch provides basic functions, from setting a random seed (for reproducability) to creating tensors.\n",
    "import torch.nn as nn # torch.nn allows us to create a neural network.\n",
    "import torch.nn.functional as F # nn.functional give us access to the activation and loss functions.\n",
    "from torch.optim import SGD # optim contains many optimizers. Here, we're using SGD, stochastic gradient descent.\n",
    "\n",
    "import matplotlib.pyplot as plt ## matplotlib allows us to draw graphs.\n",
    "import seaborn as sns ## seaborn makes it easier to draw nice-looking graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (3008424638.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__():\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class Basic_NN(nn.module):\n",
    "    def __init__():\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward():\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a neural network class by creating a class that inherits from nn.Module.\n",
    "class BasicNN(nn.Module):\n",
    "\n",
    "    def __init__(self): # __init__() is the class constructor function, and we use it to initialize the weights and biases.\n",
    "        \n",
    "        super().__init__() # initialize an instance of the parent class, nn.Model.\n",
    "        \n",
    "        ## Now create the weights and biases that we need for our neural network.\n",
    "        ## Each weight or bias is an nn.Parameter, which gives us the option to optimize the parameter by setting\n",
    "        ## requires_grad, which is short for \"requires gradient\", to True. Since we don't need to optimize any of these\n",
    "        ## parameters now, we set requires_grad=False.\n",
    "        ##\n",
    "        ## NOTE: Because our neural network is already fit to the data, we will input specific values\n",
    "        ## for each weight and bias. In contrast, if we had not already fit the neural network to the data,\n",
    "        ## we might start with a random initalization of the weights and biases.\n",
    "        self.w00 = nn.Parameter(torch.tensor(1.7), requires_grad=False)\n",
    "        self.b00 = nn.Parameter(torch.tensor(-0.85), requires_grad=False)\n",
    "        self.w01 = nn.Parameter(torch.tensor(-40.8), requires_grad=False)\n",
    "        \n",
    "        self.w10 = nn.Parameter(torch.tensor(12.6), requires_grad=False)\n",
    "        self.b10 = nn.Parameter(torch.tensor(0.0), requires_grad=False)\n",
    "        self.w11 = nn.Parameter(torch.tensor(2.7), requires_grad=False)\n",
    "\n",
    "        self.final_bias = nn.Parameter(torch.tensor(-16.), requires_grad=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, input): ## forward() takes an input value and runs it though the neural network \n",
    "                              ## illustrated at the top of this notebook. \n",
    "        \n",
    "        ## the next three lines implement the top of the neural network (using the top node in the hidden layer).\n",
    "        input_to_top_relu = input * self.w00 + self.b00\n",
    "        top_relu_output = F.relu(input_to_top_relu)\n",
    "        scaled_top_relu_output = top_relu_output * self.w01\n",
    "        \n",
    "        ## the next three lines implement the bottom of the neural network (using the bottom node in the hidden layer).\n",
    "        input_to_bottom_relu = input * self.w10 + self.b10\n",
    "        bottom_relu_output = F.relu(input_to_bottom_relu)\n",
    "        scaled_bottom_relu_output = bottom_relu_output * self.w11\n",
    "        \n",
    "        ## here, we combine both the top and bottom nodes from the hidden layer with the final bias.\n",
    "        input_to_final_relu = scaled_top_relu_output + scaled_bottom_relu_output + self.final_bias\n",
    "        \n",
    "        output = F.relu(input_to_final_relu)\n",
    "    \n",
    "        return output # output is the predicted effectiveness for a drug dose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w00 tensor(1.7000)\n",
      "b00 tensor(-0.8500)\n",
      "w01 tensor(-40.8000)\n",
      "w10 tensor(12.6000)\n",
      "b10 tensor(0.)\n",
      "w11 tensor(2.7000)\n",
      "final_bias tensor(-16.)\n"
     ]
    }
   ],
   "source": [
    "## create the neural network. \n",
    "model = BasicNN()\n",
    "\n",
    "## print out the name and value for each parameter\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_doses = torch.linspace(start=0, end=1, steps=11)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_values = model(input_doses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0100, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_values"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6eef2a13dc96940f585cf3c15521d9c910519598d91258237f5485feeed702d6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kaggle_conda_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
